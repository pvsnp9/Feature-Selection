{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicated features\n",
    "\n",
    "Often datasets contain duplicated features, that is, features that despite having different names, are identical.\n",
    "\n",
    "In addition, we may often introduce duplicated features when performing one hot encoding of categorical variables, particularly if our datasets have many and /or highly cardinal categorical variables.\n",
    "\n",
    "Identifying and removing duplicated, and therefore redundant features, is an easy first step towards feature selection and more interpretable machine learning models.\n",
    "\n",
    "Here I will demonstrate how to identify duplicated features using a dataset that I created for this course.\n",
    "\n",
    "There is no function in Pandas to find duplicated columns. So we need to write a bit code to do so.\n",
    "\n",
    "Note Finding duplicated features can be a computationally costly operation in Python, therefore depending on the size of your dataset, you might not always be able to do it.\n",
    "\n",
    "Following method on duplicated features works for both numerical and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 301)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_292</th>\n",
       "      <th>var_293</th>\n",
       "      <th>var_294</th>\n",
       "      <th>var_295</th>\n",
       "      <th>var_296</th>\n",
       "      <th>var_297</th>\n",
       "      <th>var_298</th>\n",
       "      <th>var_299</th>\n",
       "      <th>var_300</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67772.7216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  var_10  ...  \\\n",
       "0      0      0    0.0   0.00    0.0      0      0      0      0       0  ...   \n",
       "1      0      0    0.0   3.00    0.0      0      0      0      0       0  ...   \n",
       "2      0      0    0.0   5.88    0.0      0      0      0      0       0  ...   \n",
       "3      0      0    0.0  14.10    0.0      0      0      0      0       0  ...   \n",
       "4      0      0    0.0   5.76    0.0      0      0      0      0       0  ...   \n",
       "\n",
       "   var_292  var_293  var_294  var_295  var_296  var_297  var_298  var_299  \\\n",
       "0      0.0        0        0        0        0        0        0      0.0   \n",
       "1      0.0        0        0        0        0        0        0      0.0   \n",
       "2      0.0        0        0        3        0        0        0      0.0   \n",
       "3      0.0        0        0        0        0        0        0      0.0   \n",
       "4      0.0        0        0        0        0        0        0      0.0   \n",
       "\n",
       "      var_300  target  \n",
       "0      0.0000       0  \n",
       "1      0.0000       0  \n",
       "2  67772.7216       0  \n",
       "3      0.0000       0  \n",
       "4      0.0000       0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/dataset_1.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the presence of missing data.\n",
    "# (there are no missing data in this dataset)\n",
    "\n",
    "[col for col in data.columns if data[col].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 300), (15000, 300))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1), # drop the target\n",
    "    data['target'], # just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply constant and quasi-constant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cssar\\AppData\\Local\\Temp/ipykernel_14400/3063198154.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predominant = (X_train[feature].value_counts() / np.float(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove constant and quasi-constant features first:\n",
    "# we can remove the 2 types of features together with this code\n",
    "# (we used it in our previous notebook)\n",
    "\n",
    "# create an empty list\n",
    "quasi_constant_feat = []\n",
    "\n",
    "# iterate over every feature\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # find the predominant value, that is the value that is shared\n",
    "    # by most observations\n",
    "    predominant = (X_train[feature].value_counts() / np.float(\n",
    "        len(X_train))).sort_values(ascending=False).values[0]\n",
    "\n",
    "    # evaluate predominant feature: do more than 99% of the observations\n",
    "    # show 1 value?\n",
    "    if predominant > 0.998:\n",
    "        quasi_constant_feat.append(feature)\n",
    "\n",
    "len(quasi_constant_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 158), (15000, 158))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can then drop these columns from the train and test sets:\n",
    "\n",
    "X_train.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove duplicated features**\n",
    "\n",
    "To identify duplicated variables we need to iterate through all features of our dataset, and for each and every feature, try and find others that are identical, or duplicates.\n",
    "\n",
    "We will create a dictionary of {variable: duplicated variables} pairs to identify them more easily throughout the demo. Keep in mind that in a dataset, there could be 2 or more features that are identical to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "# check for duplicated features in the training set:\n",
    "\n",
    "# create an empty dictionary, where we will store \n",
    "# the groups of duplicates\n",
    "duplicated_feat_pairs = {}\n",
    "\n",
    "# create an empty list to collect features\n",
    "# that were found to be duplicated\n",
    "_duplicated_feat = []\n",
    "\n",
    "\n",
    "# iterate over every feature in our dataset:\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    \n",
    "    # this bit helps me understand where the loop is at:\n",
    "    if i % 10 == 0:  \n",
    "        print(i)\n",
    "    \n",
    "    # choose 1 feature:\n",
    "    feat_1 = X_train.columns[i]\n",
    "    \n",
    "    # check if this feature has already been identified\n",
    "    # as a duplicate of another one. If it was, it should be stored in\n",
    "    # our _duplicated_feat list.\n",
    "    \n",
    "    # If this feature was already identified as a duplicate, we skip it, if\n",
    "    # it has not yet been identified as a duplicate, then we proceed:\n",
    "    if feat_1 not in _duplicated_feat:\n",
    "    \n",
    "        # create an empty list as an entry for this feature in the dictionary:\n",
    "        duplicated_feat_pairs[feat_1] = []\n",
    "\n",
    "        # now, iterate over the remaining features of the dataset:\n",
    "        for feat_2 in X_train.columns[i + 1:]:\n",
    "\n",
    "            # check if this second feature is identical to the first one\n",
    "            if X_train[feat_1].equals(X_train[feat_2]):\n",
    "\n",
    "                # if it is identical, append it to the list in the dictionary\n",
    "                duplicated_feat_pairs[feat_1].append(feat_2)\n",
    "                \n",
    "                # and append it to our monitor list for duplicated variables\n",
    "                _duplicated_feat.append(feat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_148', 'var_199', 'var_296', 'var_250', 'var_232', 'var_269']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_duplicated_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "# let's explore the number of keys in our dictionary\n",
    "\n",
    "# we see it is 152, because 6 of the 158 were duplicates,\n",
    "# so they were not included as keys\n",
    "\n",
    "print(len(duplicated_feat_pairs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f1fe20136675b47db30784a64b23f2f74600804c7b298c8fa67f64368253755"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('whiskey_pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
